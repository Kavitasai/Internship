{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2d154c",
   "metadata": {},
   "source": [
    "1) Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249a36c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                     Header_tags\n",
      "0           Welcome to Wikipedia\n",
      "1  From today's featured article\n",
      "2               Did you know ...\n",
      "3                    In the news\n",
      "4                    On this day\n",
      "5       Today's featured picture\n",
      "6       Other areas of Wikipedia\n",
      "7    Wikipedia's sister projects\n",
      "8            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "web = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "print(web)\n",
    "soup = BeautifulSoup(web.content)\n",
    "\n",
    "header = []\n",
    "\n",
    "for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "    header.append(i.text)\n",
    "    \n",
    "df = pd.DataFrame({'Header_tags': header})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8df53",
   "metadata": {},
   "source": [
    "2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://currentaffairs.adda247.com/list-of-presidents-of-india/ and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "117f8dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                            Name       Start Date         End Date\n",
      "1            Dr. Rajendra Prasad  26 January 1950  26 January 1950\n",
      "2   Dr. Sarvepalli Radhakrishnan      13 May 1962      13 May 1962\n",
      "3              Dr. Zakir Hussain      13 May 1967      13 May 1967\n",
      "4        Varahagiri Venkata Giri       3 May 1969       3 May 1969\n",
      "5        Varahagiri Venkata Giri   24 August 1969   24 August 1969\n",
      "6           Fakhruddin Ali Ahmed   24 August 1974   24 August 1974\n",
      "7           Neelam Sanjiva Reddy     25 July 1977     25 July 1977\n",
      "8               Giani Zali Singh     25 July 1982     25 July 1982\n",
      "9         Ramaswamy Venkataraman     25 July 1987     25 July 1987\n",
      "10          Shankar Dayal Sharma     25 July 1992     25 July 1992\n",
      "11      Kocheril Raman Narayanan     25 July 1997     25 July 1997\n",
      "12        Dr. A.P.J. Abdul Kalam     25 July 2002     25 July 2002\n",
      "13                Pratibha Patil     25 July 2007     25 July 2007\n",
      "14              Pranab Mukherjee     25 July 2012     25 July 2012\n",
      "15          Shri Ram Nath Kovind     25 July 2017     25 July 2017\n",
      "16                Draupadi Murmu     21 July 2022     21 July 2022\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://currentaffairs.adda247.com/list-of-presidents-of-india/\")\n",
    "print(page)\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "pres = soup.find(\"table\")\n",
    "\n",
    "names = []\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "\n",
    "for row in pres.find_all(\"tr\")[1:]:\n",
    "    columns = row.find_all(\"td\")\n",
    "    name = columns[0].text.strip()\n",
    "    term = columns[1].text.strip()\n",
    "\n",
    "    term_parts = term.split(\" to \")\n",
    "    if len(term_parts) == 2:\n",
    "        start_date, end_date = term_parts\n",
    "    else:\n",
    "        start_date = end_date = term_parts[0]\n",
    "    \n",
    "    names.append(name)\n",
    "    start_dates.append(start_date)\n",
    "    end_dates.append(end_date)\n",
    "    \n",
    "df = pd.DataFrame({'Name': names, 'Start Date': start_dates, 'End Date': end_dates})\n",
    "\n",
    "print(df[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb41c74",
   "metadata": {},
   "source": [
    "3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "078be5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>27</td>\n",
       "      <td>3,112</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>3,102</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>40</td>\n",
       "      <td>4,558</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>2,942</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>23</td>\n",
       "      <td>2,386</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>33</td>\n",
       "      <td>3,107</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>37</td>\n",
       "      <td>3,448</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>21</td>\n",
       "      <td>1,687</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,582</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Ratings\n",
       "0     Australia      27  3,112     115\n",
       "1      Pakistan      27  3,102     115\n",
       "2         India      40  4,558     114\n",
       "3       England      28  2,942     105\n",
       "4  South Africa      23  2,386     104\n",
       "5   New Zealand      31  3,110     100\n",
       "6    Bangladesh      33  3,107      94\n",
       "7     Sri Lanka      37  3,448      93\n",
       "8   Afghanistan      21  1,687      80\n",
       "9   West Indies      38  2,582      68"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a)\n",
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "print(page)\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "top_team = soup.find('tr', class_='rankings-block__banner')\n",
    "teams.append(top_team.find('span', class_='u-hide-phablet').text.strip())\n",
    "matches.append(top_team.find('td', class_='rankings-block__banner--matches').text.strip())\n",
    "points.append(top_team.find('td', class_='rankings-block__banner--points').text.strip())\n",
    "ratings.append(top_team.find('td', class_=\"rankings-block__banner--rating u-text-right\").text.strip())\n",
    "\n",
    "other_teams = soup.find_all('tr', class_='table-body')\n",
    "for team in other_teams:\n",
    "    teams.append(team.find('span', class_='u-hide-phablet').text.strip())\n",
    "    matches.append(team.find_all('td')[2].text.strip())\n",
    "    points.append(team.find_all('td')[3].text.strip())\n",
    "    ratings.append(team.find_all('td')[4].text.strip())\n",
    "\n",
    "df = pd.DataFrame({'Team': teams,'Matches': matches,'Points': points,'Ratings': ratings})\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb51b51",
   "metadata": {},
   "source": [
    " 3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7d26517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Batsmen</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>898</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>763</td>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>796</td>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>880</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>815</td>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726</td>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>813</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>911</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>885</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>784</td>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating                Batsmen Team\n",
       "0    898             Babar Azam  PAK\n",
       "1    763           Shubman Gill  IND\n",
       "2    796  Rassie van der Dussen   SA\n",
       "3    880           David Warner  AUS\n",
       "4    815            Imam-ul-Haq  PAK\n",
       "5    726           Harry Tector  IRE\n",
       "6    813        Quinton de Kock   SA\n",
       "7    911            Virat Kohli  IND\n",
       "8    885           Rohit Sharma  IND\n",
       "9    784           Fakhar Zaman  PAK"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cric = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "print(cric)\n",
    "\n",
    "soup = BeautifulSoup(cric.content)\n",
    "\n",
    "players = soup.find('table',class_=\"table rankings-table\").find_all('tr')\n",
    "\n",
    "batsmen =[]\n",
    "teams =[]\n",
    "ratings =[]\n",
    "\n",
    "for player in players[1:11]:\n",
    "    columns = player.find_all('td')\n",
    "    \n",
    "    if len(columns) >= 5:\n",
    "        rating = columns[4].get_text(strip=True).split(\" \")[0]\n",
    "        batsman = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "\n",
    "        batsmen.append(batsman)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "\n",
    "df = pd.DataFrame({\"Rating\":ratings,'Batsmen':batsmen,'Team':teams})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdcc1c1",
   "metadata": {},
   "source": [
    "3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "983f5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bowler</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>692</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666</td>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>663</td>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>657</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>656</td>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>655</td>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>643</td>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>635</td>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating            Bowler Team\n",
       "0    692    Josh Hazlewood  AUS\n",
       "1    666    Mitchell Starc  AUS\n",
       "2    666       Trent Boult   NZ\n",
       "3    663        Adam Zampa  AUS\n",
       "4    658        Matt Henry   NZ\n",
       "5    657  Mujeeb Ur Rahman  AFG\n",
       "6    656     Kuldeep Yadav  IND\n",
       "7    655       Rashid Khan  AFG\n",
       "8    643    Mohammed Siraj  IND\n",
       "9    635    Shaheen Afridi  PAK"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cric = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "print(cric)\n",
    "\n",
    "soup = BeautifulSoup(cric.content)\n",
    "\n",
    "players = soup.find('table',class_=\"table rankings-table\").find_all('tr')\n",
    "\n",
    "bowlers =[]\n",
    "teams =[]\n",
    "ratings =[]\n",
    "\n",
    "for player in players[1:11]:\n",
    "    columns = player.find_all('td')\n",
    "    \n",
    "    if len(columns) >= 5:\n",
    "        rating = columns[3].get_text(strip=True).split(\" \")[0]\n",
    "        bowler = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "\n",
    "        bowlers.append(bowler)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "\n",
    "df = pd.DataFrame({\"Rating\":ratings,'Bowler':bowlers,'Team':teams})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a97d96",
   "metadata": {},
   "source": [
    "4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0334b5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>26</td>\n",
       "      <td>4,290</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>31</td>\n",
       "      <td>3,875</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>30</td>\n",
       "      <td>3,039</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>28</td>\n",
       "      <td>2,688</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2,743</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>17</td>\n",
       "      <td>1,284</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>12</td>\n",
       "      <td>820</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>13</td>\n",
       "      <td>883</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Rating\n",
       "0     Australia      26  4,290    165\n",
       "1       England      31  3,875    125\n",
       "2  South Africa      26  3,098    119\n",
       "3         India      30  3,039    101\n",
       "4   New Zealand      28  2,688     96\n",
       "5   West Indies      29  2,743     95\n",
       "6    Bangladesh      17  1,284     76\n",
       "7     Sri Lanka      12    820     68\n",
       "8      Thailand      13    883     68\n",
       "9      Pakistan      27  1,678     62"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cric = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "print(cric)\n",
    "\n",
    "soup = BeautifulSoup(cric.content)\n",
    "\n",
    "players = soup.find('div',class_=\"rankings-block__container full rankings-table\").find_all('tr')\n",
    "\n",
    "teams =[]\n",
    "matches =[]\n",
    "ratings =[]\n",
    "points =[]\n",
    "\n",
    "for player in players[1:11]:\n",
    "    columns = player.find_all('td')\n",
    "    \n",
    "    if len(columns) >= 5:\n",
    "        rating = columns[4].text.strip()\n",
    "        match = columns[2].text.strip()\n",
    "        team = columns[1].text.strip().split('\\n')[0]\n",
    "        point = columns[3].text.strip()\n",
    "\n",
    "        points.append(point)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "        matches.append(match)\n",
    "        \n",
    "\n",
    "df = pd.DataFrame({\"Team\":teams,'Matches':matches,'Points':points,\"Rating\":ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281a2c6",
   "metadata": {},
   "source": [
    "4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe0db59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Batsmen</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801</td>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>751</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>743</td>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>708</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>708</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>702</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>694</td>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>686</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>682</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>618</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating               Batsmen Team\n",
       "0    801  Natalie Sciver-Brunt  ENG\n",
       "1    751           Beth Mooney  AUS\n",
       "2    743   Chamari Athapaththu   SL\n",
       "3    708       Laura Wolvaardt   SA\n",
       "4    708       Smriti Mandhana  IND\n",
       "5    702          Alyssa Healy  AUS\n",
       "6    694      Harmanpreet Kaur  IND\n",
       "7    686          Ellyse Perry  AUS\n",
       "8    682           Meg Lanning  AUS\n",
       "9    618       Stafanie Taylor   WI"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cric = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "print(cric)\n",
    "\n",
    "soup = BeautifulSoup(cric.content)\n",
    "\n",
    "players = soup.find('table',class_=\"table rankings-table\").find_all('tr')\n",
    "\n",
    "batsmen =[]\n",
    "teams =[]\n",
    "ratings =[]\n",
    "\n",
    "for player in players[1:11]:\n",
    "    columns = player.find_all('td')\n",
    "    \n",
    "    if len(columns) >= 5:\n",
    "        rating = columns[3].get_text(strip=True).split(\" \")[0]\n",
    "        batsman = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "\n",
    "        batsmen.append(batsman)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "\n",
    "df = pd.DataFrame({\"Rating\":ratings,'Batsmen':batsmen,'Team':teams})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369d2e7",
   "metadata": {},
   "source": [
    "4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50109b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Batsmen</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382</td>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>362</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>329</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>328</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>312</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>241</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>233</td>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>217</td>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rating               Batsmen Team\n",
       "0    398  Natalie Sciver-Brunt  ENG\n",
       "1    389      Ashleigh Gardner  AUS\n",
       "2    382       Hayley Matthews   WI\n",
       "3    362        Marizanne Kapp   SA\n",
       "4    329          Ellyse Perry  AUS\n",
       "5    328           Amelia Kerr   NZ\n",
       "6    312         Deepti Sharma  IND\n",
       "7    241         Jess Jonassen  AUS\n",
       "8    233         Sophie Devine   NZ\n",
       "9    217              Nida Dar  PAK"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cric = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "print(cric)\n",
    "\n",
    "soup = BeautifulSoup(cric.content)\n",
    "\n",
    "players = soup.find('table',class_=\"table rankings-table\").find_all('tr')\n",
    "\n",
    "batsmen =[]\n",
    "teams =[]\n",
    "ratings =[]\n",
    "\n",
    "for player in players[1:11]:\n",
    "    columns = player.find_all('td')\n",
    "    \n",
    "    if len(columns) >= 5:\n",
    "        rating = columns[3].get_text(strip=True).split(\" \")[0]\n",
    "        batsman = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "\n",
    "        batsmen.append(batsman)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "\n",
    "df = pd.DataFrame({\"Rating\":ratings,'Batsmen':batsmen,'Team':teams})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217b26b",
   "metadata": {},
   "source": [
    "5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data framei) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "834e33f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                                             Headline                Time  \\\n",
      "0   These are the 11 sectors of the S&P 500 — and ...          46 Min Ago   \n",
      "1   No. 1 tip for starting a side hustle, from 2 m...          1 Hour Ago   \n",
      "2   These are the top 10 states for young workers,...         2 Hours Ago   \n",
      "3   Why health insurance is poised to make inflati...         2 Hours Ago   \n",
      "4   Hollywood pays a steep price for never really ...         3 Hours Ago   \n",
      "5   Disney asset sales won't break the bank, but t...         3 Hours Ago   \n",
      "6   It’s been one year since the Ethereum merge. H...         3 Hours Ago   \n",
      "7   Behind Warren Buffett's $100 billion-plus bet ...         3 Hours Ago   \n",
      "8   One individual investor favorite has endured e...         3 Hours Ago   \n",
      "9   Stellantis offers raises, inflation protection...        21 Hours Ago   \n",
      "10  Strong retail sales despite stubborn inflation...        21 Hours Ago   \n",
      "11  4 things the world's longest-living people do ...        24 Hours Ago   \n",
      "12  How Olipop's founders started a soda brand bri...  September 16, 2023   \n",
      "13  Here are three things we're watching in the ma...  September 16, 2023   \n",
      "14  U.S. states where property taxes are highest—N...  September 16, 2023   \n",
      "15  The No. 1 thing successful parents who raise t...  September 16, 2023   \n",
      "16  Mark Cuban: If someone says they can make you ...  September 16, 2023   \n",
      "17  Top investor Jenny Harrington breaks down her ...  September 16, 2023   \n",
      "18  3 financial tips for couples moving in togethe...  September 16, 2023   \n",
      "19  Analysts said obesity drugs would be blockbust...  September 16, 2023   \n",
      "20  Analysts see stocks like Microsoft offering 'd...  September 16, 2023   \n",
      "21  Stocks churn with the S&P 500 sitting at the s...  September 16, 2023   \n",
      "22  We gave the $2.1 million Rimac Nevera electric...  September 16, 2023   \n",
      "23  Trump lashes out at Jack Smith's bid for parti...  September 15, 2023   \n",
      "24       Cramer's Lightning Round: Sell Joby Aviation  September 15, 2023   \n",
      "25  Cramer's week ahead: Pay attention to the Fede...  September 15, 2023   \n",
      "26  Okta CEO on MGM breach: Companies are under 'm...  September 15, 2023   \n",
      "27  Jack Smith wants Trump barred from posting on ...  September 15, 2023   \n",
      "28  Adobe falls after posting quarterly results. H...  September 15, 2023   \n",
      "29  Bernie Sanders calls out automaker CEOs at UAW...  September 15, 2023   \n",
      "\n",
      "                                            News Link  \n",
      "0   https://www.cnbc.com/2023/09/17/the-11-sectors...  \n",
      "1   https://www.cnbc.com/2023/09/17/rachel-jimenez...  \n",
      "2   https://www.cnbc.com/2023/09/17/these-are-the-...  \n",
      "3   https://www.cnbc.com/2023/09/17/why-health-ins...  \n",
      "4   https://www.cnbc.com/2023/09/17/hollywood-stre...  \n",
      "5   https://www.cnbc.com/2023/09/17/disney-asset-s...  \n",
      "6   https://www.cnbc.com/2023/09/17/its-been-one-y...  \n",
      "7   https://www.cnbc.com/2023/09/17/buffett-calls-...  \n",
      "8   https://www.cnbc.com/2023/09/17/one-individual...  \n",
      "9   https://www.cnbc.com/2023/09/16/stellantis-off...  \n",
      "10  https://www.cnbc.com/2023/09/16/strong-retail-...  \n",
      "11  https://www.cnbc.com/2023/09/16/4-things-the-w...  \n",
      "12  https://www.cnbc.com/2023/09/16/how-olipops-fo...  \n",
      "13  https://www.cnbc.com/2023/09/16/here-are-three...  \n",
      "14  https://www.cnbc.com/2023/09/16/us-states-wher...  \n",
      "15  https://www.cnbc.com/2023/09/16/the-no-1-paren...  \n",
      "16  https://www.cnbc.com/2023/09/16/mark-cuban-if-...  \n",
      "17  https://www.cnbc.com/2023/09/16/top-investor-j...  \n",
      "18  https://www.cnbc.com/2023/09/16/3-financial-ti...  \n",
      "19  https://www.cnbc.com/2023/09/16/analysts-raisi...  \n",
      "20  https://www.cnbc.com/2023/09/16/stocks-like-mi...  \n",
      "21  https://www.cnbc.com/2023/09/16/stocks-churn-w...  \n",
      "22  https://www.cnbc.com/2023/09/16/rimac-nevera-e...  \n",
      "23  https://www.cnbc.com/2023/09/15/trump-lashes-o...  \n",
      "24  https://www.cnbc.com/2023/09/15/cramers-lightn...  \n",
      "25  https://www.cnbc.com/2023/09/15/cramers-week-a...  \n",
      "26  https://www.cnbc.com/2023/09/15/okta-ceo-on-mg...  \n",
      "27  https://www.cnbc.com/2023/09/15/special-counse...  \n",
      "28  https://www.cnbc.com/2023/09/15/adobe-falls-af...  \n",
      "29  https://www.cnbc.com/2023/09/15/sanders-to-add...  \n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "print(page)\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "news = soup.find_all('div', class_=\"LatestNews-container\")\n",
    "\n",
    "headlines = []\n",
    "times = []\n",
    "links = []\n",
    "for item in news:\n",
    "    headline = item.find('a', class_='LatestNews-headline')\n",
    "    time = item.find('span',class_=\"LatestNews-wrapper\")\n",
    "    link = headline['href'] if headline else None\n",
    "    \n",
    "    headline_text = headline.text.strip() if headline else None\n",
    "    time_text = time.text.strip() if time else None\n",
    "    \n",
    "    headlines.append(headline_text)\n",
    "    times.append(time_text)\n",
    "    links.append(link)\n",
    "    \n",
    "df = pd.DataFrame({'Headline': headlines, 'Time': times, 'News Link': links})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc7e0f",
   "metadata": {},
   "source": [
    "6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "Scrape below mentioned details and make data framei) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8b988a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                                                Title              Author  \\\n",
      "0                                  Da Vinci Code,The          Brown, Dan    \n",
      "1               Harry Potter and the Deathly Hallows       Rowling, J.K.    \n",
      "2           Harry Potter and the Philosopher's Stone       Rowling, J.K.    \n",
      "3          Harry Potter and the Order of the Phoenix       Rowling, J.K.    \n",
      "4                               Fifty Shades of Grey        James, E. L.    \n",
      "..                                                ...                 ...   \n",
      "95                                         Ghost,The      Harris, Robert    \n",
      "96                    Happy Days with the Naked Chef       Oliver, Jamie    \n",
      "97             Hunger Games,The:Hunger Games Trilogy    Collins, Suzanne    \n",
      "98   Lost Boy,The:A Foster Child's Search for the ...       Pelzer, Dave    \n",
      "99   Jamie's Ministry of Food:Anyone Can Learn to ...      Oliver, Jamie    \n",
      "\n",
      "   Volume Sales          Publisher                          Genre  \n",
      "0    5,094,805         Transworld    Crime, Thriller & Adventure   \n",
      "1    4,475,152         Bloomsbury             Children's Fiction   \n",
      "2    4,200,654         Bloomsbury             Children's Fiction   \n",
      "3    4,179,479         Bloomsbury             Children's Fiction   \n",
      "4    3,758,936       Random House                Romance & Sagas   \n",
      "..          ...                ...                            ...  \n",
      "95     807,311       Random House     General & Literary Fiction   \n",
      "96     794,201            Penguin          Food & Drink: General   \n",
      "97     792,187    Scholastic Ltd.            Young Adult Fiction   \n",
      "98     791,507              Orion             Biography: General   \n",
      "99     791,095            Penguin          Food & Drink: General   \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "page = requests.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "print(page)\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "titles = [] \n",
    "authors = [] \n",
    "volume_sales = [] \n",
    "publishers = []\n",
    "genres = []\n",
    "\n",
    "books = soup.find('table', class_='in-article sortable').find_all('tr')\n",
    "\n",
    "for row in books[1:]:  \n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if len(columns) >= 5:\n",
    "        title = columns[1].text\n",
    "        author = columns[2].text\n",
    "        sales = columns[3].text\n",
    "        publisher = columns[4].text\n",
    "        genre = columns[5].text\n",
    "\n",
    "        titles.append(title)\n",
    "        authors.append(author)\n",
    "        volume_sales.append(sales)\n",
    "        publishers.append(publisher)\n",
    "        genres.append(genre)\n",
    "\n",
    "df = pd.DataFrame({'Title': titles,'Author': authors,'Volume Sales': volume_sales,'Publisher': publishers,'Genre': genres})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523414f",
   "metadata": {},
   "source": [
    "7) Write a python program to scrape mentioned details from dineout.co.inand make data frame\n",
    "\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6bfa2ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                             Titles  \\\n",
      "0                   Castle Barbeque   \n",
      "1                        Cafe Knosh   \n",
      "2                 Castle's Barbeque   \n",
      "3                       India Grill   \n",
      "4              The Barbeque Company   \n",
      "5                    Delhi Barbeque   \n",
      "6  The Monarch - Bar Be Que Village   \n",
      "7                 Indian Grill Room   \n",
      "8                The Barbeque Times   \n",
      "\n",
      "                                            Location       Cousine  \\\n",
      "0                     Connaught Place, Central Delhi       Chinese   \n",
      "1  The Leela Ambience Convention Hotel,Shahdara, ...       Italian   \n",
      "2             Pacific Mall,Tagore Garden, West Delhi       Chinese   \n",
      "3               Hilton Garden Inn,Saket, South Delhi  North Indian   \n",
      "4                 Gardens Galleria,Sector 38A, Noida  North Indian   \n",
      "5     Taurus Sarovar Portico,Mahipalpur, South Delhi  North Indian   \n",
      "6  Indirapuram Habitat Centre,Indirapuram, Ghaziabad  North Indian   \n",
      "7   Suncity Business Tower,Golf Course Road, Gurgaon  North Indian   \n",
      "8              M2K Corporate Park,Sector 51, Gurgaon  North Indian   \n",
      "\n",
      "                                           Image url Rating  \n",
      "0  https://im1.dineout.co.in/images/uploads/resta...      4  \n",
      "1  https://im1.dineout.co.in/images/uploads/resta...    4.3  \n",
      "2  https://im1.dineout.co.in/images/uploads/resta...    3.9  \n",
      "3  https://im1.dineout.co.in/images/uploads/resta...    3.9  \n",
      "4  https://im1.dineout.co.in/images/uploads/resta...    3.9  \n",
      "5  https://im1.dineout.co.in/images/uploads/resta...    3.7  \n",
      "6  https://im1.dineout.co.in/images/uploads/resta...    3.8  \n",
      "7  https://im1.dineout.co.in/images/uploads/resta...    4.3  \n",
      "8  https://im1.dineout.co.in/images/uploads/resta...    4.1  \n"
     ]
    }
   ],
   "source": [
    "page= requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "print(page)\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "name =[] \n",
    "locs =[] \n",
    "cousine =[] \n",
    "img =[]\n",
    "rating = []\n",
    "\n",
    "for i in soup.find_all('div',class_ = \"restnt-info cursor\"):\n",
    "    name.append(i.a.text)\n",
    "    \n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    locs.append(i.text)\n",
    "\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cousine.append(i.a.text)\n",
    "\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    img.append(i['data-src'])\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "df = pd.DataFrame({'Titles':name,'Location':locs,'Cousine':cousine,'Image url':img,'Rating':rating})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116832c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
