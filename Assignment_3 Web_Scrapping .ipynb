{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1530b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from googlesearch import search\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import selenium.common.exceptions\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674d41c",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product from www.amazon.in. The\n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for\n",
    "guitars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "155e510e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Product : guitar\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "def product_details(product):\n",
    "    \n",
    "    driver.get('https://www.amazon.in/')\n",
    "    \n",
    "    page = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "    #page = driver.find_element(By.CSS_SELECTOR,'.nav-input.nav-progressive-attribute')\n",
    "    page.send_keys(product)\n",
    "    page.send_keys(Keys.RETURN)\n",
    "\n",
    "product = input(\"Enter the Product : \")\n",
    "product_details(product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4be5a",
   "metadata": {},
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages of your search\n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then\n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dd5151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_urls = []\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    url=driver.find_elements(By.XPATH, '//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]') \n",
    "    for i in url: \n",
    "        product_urls.append(i.get_attribute(\"href\"))  \n",
    "        \n",
    "    nxt_button=driver.find_element(By.XPATH, '//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')\n",
    "    nxt_button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "900a7bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "831deafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guitar data scrapping complete\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "product_name = []\n",
    "price = []\n",
    "return_exchange = []\n",
    "expected_delivery = []\n",
    "availability = []\n",
    "url_list = []\n",
    "\n",
    "for url in product_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        brands = driver.find_element(By.XPATH, '//span[@class=\"a-size-base po-break-word\"]')\n",
    "        brand.append(brands.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        brand.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        product_names = driver.find_element(By.XPATH, '//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "        product_name.append(product_names.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        product_name.append(\"-\")\n",
    "    \n",
    "    try:\n",
    "        prices = driver.find_element(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "        price.append(prices.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        price.append(\"-\")\n",
    "    \n",
    "    try:\n",
    "        returns = driver.find_element(By.XPATH, '//li[@class=\"a-carousel-card tw-scroll-carousel-element\"][3]')\n",
    "        return_exchange.append(returns.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        return_exchange.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        delivery = driver.find_element(By.XPATH, '//div[@class=\"a-spacing-base\"]')\n",
    "        expected_delivery.append(delivery.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        expected_delivery.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        available = driver.find_element(By.XPATH, '//span[@class=\"a-size-medium a-color-success\"]')\n",
    "        availability.append(available.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        availability.append(\"-\")\n",
    "        \n",
    "    url_list.append(url)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Brand Name\" : brand,\n",
    "    \"Product Name\" : product_name,\n",
    "    \"Price\" : price,\n",
    "    \"Return/Exchange\" : return_exchange,\n",
    "    \"Expected Delivery\" :expected_delivery,\n",
    "    \"Availability\" : availability,\n",
    "    \"URL\" : url_list\n",
    "})\n",
    "\n",
    "df.to_csv(f\"{product} details on amazon.csv\", index=False)\n",
    "print(f\"{product} data scrapping complete\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845bdc5e",
   "metadata": {},
   "source": [
    "3. Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "deac91a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://images.google.com/')\n",
    "\n",
    "page = driver.find_element(By.CLASS_NAME,'gLFyf')\n",
    "page.send_keys('cakes')\n",
    "page.send_keys(Keys.RETURN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80cda470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 0 of 10 images\n",
      "Downloading 1 of 10 images\n",
      "Downloading 2 of 10 images\n",
      "Downloading 3 of 10 images\n",
      "Downloading 4 of 10 images\n",
      "Downloading 5 of 10 images\n",
      "Downloading 6 of 10 images\n",
      "Downloading 7 of 10 images\n",
      "Downloading 8 of 10 images\n",
      "Downloading 9 of 10 images\n",
      "Downloading 10 of 10 images\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    \n",
    "images=driver.find_elements (By.XPATH, '//img[@class=\"rg_i Q4LuWd\"]')\n",
    "\n",
    "img_urls = []\n",
    "\n",
    "for image in images:\n",
    "    source= image.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if(source[0:4] =='http'):\n",
    "            img_urls.append(source)\n",
    "            \n",
    "for i in range(len(img_urls)):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 10))\n",
    "    response= requests.get(img_urls[i])\n",
    "    file = open(r\"C:\\Users\\user\\OneDrive\\Documents\\FlipRobo\"+ str(i)+ \".jpg\", \"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e1916",
   "metadata": {},
   "source": [
    "4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18cb3639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Smart Phone : Oneplus Nord, pixel 4A\n",
      "Data saved to smartphone_data.csv\n"
     ]
    }
   ],
   "source": [
    "def smart_phone(phone):\n",
    "    driver = webdriver.Chrome()\n",
    "    try:\n",
    "        driver.get('https://www.flipkart.com/')\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        search_area = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "        search_area.send_keys(phone)\n",
    "        search_area.send_keys(Keys.RETURN)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        product = []\n",
    "\n",
    "        products = driver.find_elements(By.XPATH, '//div[@class=\"_4rR01T\"]')\n",
    "        prices = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3 _1_WHN1\"]') \n",
    "        ram = driver.find_elements(By.XPATH, '//ul[@class=\"_1xgFaf\"]/li[1]')\n",
    "        camera = driver.find_elements(By.XPATH, '//ul[@class=\"_1xgFaf\"]/li[3]')\n",
    "        display = driver.find_elements(By.XPATH, '//ul[@class=\"_1xgFaf\"]/li[2]')\n",
    "        battery = driver.find_elements(By.XPATH, '//ul[@class=\"_1xgFaf\"]/li[4]')\n",
    "        urls = driver.find_elements(By.XPATH, '//div[@class=\"_2kHMtA\"]/a')\n",
    "\n",
    "        for i in range(len(products)):\n",
    "            try:\n",
    "                product_dict = {\n",
    "                    \"Brand Name\": products[i].text.split(' ')[0],\n",
    "                    \"SmartPhone Name\": products[i].text.split('(')[0],\n",
    "                    \"Colour\": products[i].text.split('(')[1].split(',')[0],\n",
    "                    \"Price\": prices[i].text if prices and i < len(prices) else '-',\n",
    "                    \"RAM\": ram[i].text.split('|')[0] if ram and i < len(ram) else '-',\n",
    "                    \"ROM\": ram[i].text.split('|')[1] if ram and i < len(ram) else '-',\n",
    "                    \"Primary Camera\": camera[i].text.split('|')[0] if camera and i < len(camera) else '-',\n",
    "                    \"Secondary Camera\": camera[i].text.split('|')[1] if camera and i < len(camera) else '-',\n",
    "                    \"Display\": display[i].text if display and i < len(display) else '-',\n",
    "                    \"Battery\": battery[i].text if battery and i < len(battery) else '-',\n",
    "                    \"URL\": urls[i].get_attribute('href') if urls and i < len(urls) else '-'\n",
    "                }\n",
    "\n",
    "                product.append(product_dict)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scraping: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(product)\n",
    "    df.to_csv('smartphone_data.csv', index=False)\n",
    "    print(\"Data saved to smartphone_data.csv\")\n",
    "    driver.quit()\n",
    "\n",
    "phone = input(\"Enter a Smart Phone : \")\n",
    "smart_phone(phone)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a5e1b",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8679018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city name: delhi\n",
      "Coordinates for delhi: Latitude 28.6442873, Longitude 76.7635522\n"
     ]
    }
   ],
   "source": [
    "def get_coordinates(city):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.google.com/maps\")\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "    search_box = driver.find_element(By.NAME, \"q\")\n",
    "    search_box.send_keys(city)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    current_url = driver.current_url\n",
    "    coordinates = extract_coordinates_from_url(current_url)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "def extract_coordinates_from_url(url):\n",
    "    match = re.search(r'@(-?\\d+\\.\\d+),(-?\\d+\\.\\d+)', url)\n",
    "    if match:\n",
    "        latitude = float(match.group(1))\n",
    "        longitude = float(match.group(2))\n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "city = input(\"Enter the city name: \")\n",
    "coordinates = get_coordinates(city)\n",
    "\n",
    "if coordinates:\n",
    "    print(f\"Coordinates for {city}: Latitude {coordinates[0]}, Longitude {coordinates[1]}\")\n",
    "else:\n",
    "    print(f\"Coordinates not found for {city}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a52d0e2",
   "metadata": {},
   "source": [
    "6. Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00a0b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.digit.in/')\n",
    "\n",
    "web = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/a')\n",
    "web.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "page = driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div/div[2]/div[1]/div[3]/div[6]/p/a')\n",
    "page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c64c0bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Operating System</th>\n",
       "      <th>Display Size</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple MacBook Air 2022 M2 MLY03HN/A</td>\n",
       "      <td>iOS</td>\n",
       "      <td>13.6</td>\n",
       "      <td>2560 x 1600</td>\n",
       "      <td>Apple M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book3 Pro 360</td>\n",
       "      <td>13.6</td>\n",
       "      <td>14</td>\n",
       "      <td>2880 x 1800</td>\n",
       "      <td>13th Gen Intel Core i7-1360P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Yoga 9i13th Gen Core i7-1360P</td>\n",
       "      <td>2560 x 1600</td>\n",
       "      <td>14.2</td>\n",
       "      <td>3840 x 2400</td>\n",
       "      <td>12th Gen Intel EVO Core i7-1260P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple MacBook Pro M2 (2023-MPHK3HN/A)</td>\n",
       "      <td>Apple M2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1920 x 1080</td>\n",
       "      <td>11th Gen Intel Core i7-11390H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell XPS 13 Plus D560075WIN9S 12th Gen Core i7...</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Swift X SFX16-51G 11th Gen Core i7-11390H</td>\n",
       "      <td>14</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Operating System  \\\n",
       "0                Apple MacBook Air 2022 M2 MLY03HN/A              iOS   \n",
       "1                       Samsung Galaxy Book3 Pro 360             13.6   \n",
       "2               Lenovo Yoga 9i13th Gen Core i7-1360P      2560 x 1600   \n",
       "3              Apple MacBook Pro M2 (2023-MPHK3HN/A)         Apple M2   \n",
       "4  Dell XPS 13 Plus D560075WIN9S 12th Gen Core i7...  Windows 11 Home   \n",
       "5     Acer Swift X SFX16-51G 11th Gen Core i7-11390H               14   \n",
       "\n",
       "  Display Size   Resolution                         Processor  \n",
       "0         13.6  2560 x 1600                          Apple M2  \n",
       "1           14  2880 x 1800      13th Gen Intel Core i7-1360P  \n",
       "2         14.2  3840 x 2400  12th Gen Intel EVO Core i7-1260P  \n",
       "3         13.4  1920 x 1080     11th Gen Intel Core i7-11390H  \n",
       "4           16            -                                 -  \n",
       "5            -            -                                 -  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product =[]\n",
    "\n",
    "name = driver.find_elements(By.XPATH,'//h3[@class=\"font130 mt0 mb10 mobilesblockdisplay \"]')\n",
    "operating_system = driver.find_elements(By.XPATH,'//div[@class=\"woo_code_zone_loop clearbox\"]/div/div/span[2]')\n",
    "display_size = driver.find_elements(By.XPATH,'//div[@class=\"woo_code_zone_loop clearbox\"]/div[2]/div/span[2]')\n",
    "resolution = driver.find_elements(By.XPATH,'//div[@class=\"woo_code_zone_loop clearbox\"]/div[3]/div/span[2]')\n",
    "processor = driver.find_elements(By.XPATH,'//div[@class=\"woo_code_zone_loop clearbox\"]/div[4]/div/span[2]')\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    \n",
    "    product_dict = {\n",
    "        \"Name\" : name[i].text,\n",
    "        \"Operating System\" : operating_system[i].text if i < len(operating_system) else '-',\n",
    "        \"Display Size\" : display_size[i].text if i < len(display_size) else '-',\n",
    "        \"Resolution\" : resolution[i].text if i < len(resolution) else '-',\n",
    "        \"Processor\" : processor[i].text if i < len(processor) else '-',\n",
    "    }\n",
    "    \n",
    "    product.append(product_dict)\n",
    "        \n",
    "df = pd.DataFrame(product)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67451fa",
   "metadata": {},
   "source": [
    "7. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped:\n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19c82c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.forbes.com/')\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "page = driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div[1]/div/div')\n",
    "page.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "web = driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div[1]/div/div[2]/ul/li[2]/div[1]')\n",
    "web.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/div/main/div/section/div[2]/div/div/div[1]/div/div[2]/div/div/a/h2')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1990714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Name  Rank Net Worth Age    Citizenship  \\\n",
      "0     Bernard Arnault & family     1    $211 B  74         France   \n",
      "1                    Elon Musk     2    $180 B  51  United States   \n",
      "2                   Jeff Bezos     3    $114 B  59  United States   \n",
      "3                Larry Ellison     4    $107 B  78  United States   \n",
      "4               Warren Buffett     5    $106 B  92  United States   \n",
      "...                        ...   ...       ...  ..            ...   \n",
      "2635                   Yu Rong  2540      $1 B  51          China   \n",
      "2636    Richard Yuengling, Jr.  2540      $1 B  80  United States   \n",
      "2637             Zhang Gongyun  2540      $1 B  60          China   \n",
      "2638    Zhang Guiping & family  2540      $1 B  71          China   \n",
      "2639               Inigo Zobel  2540      $1 B  66    Philippines   \n",
      "\n",
      "                            Source               Industry  \n",
      "0                             LVMH       Fashion & Retail  \n",
      "1                    Tesla, SpaceX             Automotive  \n",
      "2                           Amazon             Technology  \n",
      "3                           Oracle             Technology  \n",
      "4               Berkshire Hathaway  Finance & Investments  \n",
      "...                            ...                    ...  \n",
      "2635                Health clinics             Healthcare  \n",
      "2636                          Beer        Food & Beverage  \n",
      "2637  Tyre manufacturing machinery          Manufacturing  \n",
      "2638                   Real estate            Real Estate  \n",
      "2639                   Diversified            Diversified  \n",
      "\n",
      "[2640 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "billionairs =[]\n",
    "start = 0\n",
    "end = 14\n",
    "\n",
    "for i in range(start,end):\n",
    "    name = driver.find_elements(By.XPATH,'//div[@class=\"TableRow_rowContainer__IC1Tv\"]/div/div[2]/div/div/div[2]')\n",
    "    rank = driver.find_elements(By.XPATH,'//div[@class=\"TableRow_rowContainer__IC1Tv\"]/div/div[2]/div/div/div[1]')\n",
    "    net_worth = driver.find_elements(By.XPATH,'//div[@class=\"TableRow_rowContainer__IC1Tv\"]/div/div[2]/div/div/div[3]')\n",
    "    age = driver.find_elements(By.XPATH,'//div[@class=\"TableRow_rowContainer__IC1Tv\"]/div/div[2]/div/div/div[4]')\n",
    "    citizenship = driver.find_elements(By.XPATH,'//div[@class=\"TableRow_rowContainer__IC1Tv\"]/div/div[2]/div/div/div[5]')\n",
    "    source = driver.find_elements(By.XPATH,'//div[@class=\"TableRow_rowContainer__IC1Tv\"]/div/div[2]/div/div/div[6]')\n",
    "    industry = driver.find_elements(By.XPATH,'//div[@class=\"TableRow_rowContainer__IC1Tv\"]/div/div[2]/div/div/div[7]')\n",
    "    \n",
    "    name.pop(1)\n",
    "    name.pop(1)\n",
    "    rank.pop(1)\n",
    "    rank.pop(1)\n",
    "    rank.pop(1)\n",
    "    \n",
    "    for i in range(len(name)):\n",
    "        \n",
    "        billionair = {\n",
    "            \"Name\" : name[i].text if i < len(net_worth) else '-',\n",
    "            \"Rank\" : rank[i].text if i < len(net_worth) else '-',\n",
    "            \"Net Worth\" : net_worth[i].text if i < len(net_worth) else '-',\n",
    "            \"Age\" : age[i].text if i < len(age) else '-',\n",
    "            \"Citizenship\" : citizenship[i].text if i < len(citizenship) else '-',\n",
    "            \"Source\" : source[i].text if i < len(source) else '-',\n",
    "            \"Industry\" : industry[i].text if i < len(industry) else '-'\n",
    "        }\n",
    "        billionairs.append(billionair)\n",
    "    try:    \n",
    "        next_button = driver.find_element(By.XPATH,'//span[@class=\"Pagination_bubbleArrow__WFrX4 Pagination_paginationBtnNext__IOwqm\"]') \n",
    "        next_button.click()\n",
    "        \n",
    "    except Exception:\n",
    "        break\n",
    "        time.sleep(3)\n",
    "        \n",
    "df = pd.DataFrame(billionairs)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456a40c",
   "metadata": {},
   "source": [
    "8. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted\n",
    "from any YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b94ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.youtube.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df10167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.find_element(By.XPATH,'/html/body/ytd-app/div[1]/div/ytd-masthead/div[4]/div[2]/ytd-searchbox/form/div[1]/div[1]/input')\n",
    "page.send_keys('sunny morning')\n",
    "page.send_keys(Keys.RETURN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24473666",
   "metadata": {},
   "outputs": [],
   "source": [
    "web = driver.find_element(By.XPATH,'/html/body/ytd-app/div[1]/ytd-page-manager/ytd-search/div[1]/ytd-two-column-search-results-renderer/div/ytd-section-list-renderer/div[2]/ytd-item-section-renderer/div[3]/ytd-video-renderer[3]/div[1]/div/div[1]/div/h3/a/yt-formatted-string')\n",
    "web.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea422938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Comments Comment Upvotes  \\\n",
      "0    Welcome to Soothing Relaxation! My name is Ped...            1.7K   \n",
      "1    From the beginning I was immersed in this kind...             355   \n",
      "2    This is the most soothing and relaxing video I...               3   \n",
      "3          Love the music  Really relaxing, keep it up               2   \n",
      "4    Oi tudo bem!!\\nEu gosto muito dessa música. Ou...                   \n",
      "..                                                 ...             ...   \n",
      "495  this is a really relaxing thing to listen to m...                   \n",
      "496  I use to always see these if you're seeing thi...                   \n",
      "497  I think \\n\\nI might be late on commenting on t...              71   \n",
      "498                            wow ang ganda ng music.                   \n",
      "499                       Awesome music and relaxing..               1   \n",
      "\n",
      "              Comment Time  \n",
      "0    8 months ago (edited)  \n",
      "1             5 months ago  \n",
      "2               2 days ago  \n",
      "3               2 days ago  \n",
      "4      3 days ago (edited)  \n",
      "..                     ...  \n",
      "495           3 months ago  \n",
      "496           3 months ago  \n",
      "497            3 years ago  \n",
      "498           2 months ago  \n",
      "499            3 weeks ago  \n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(60):\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "    time.sleep(50)\n",
    "    \n",
    "comments = driver.find_elements(By.XPATH, '//yt-formatted-string[@id=\"content-text\"]')\n",
    "comment_upvotes = driver.find_elements(By.XPATH, '//div[@class=\"style-scope ytd-comment-action-buttons-renderer\"]/span[2]')\n",
    "comment_times = driver.find_elements(By.XPATH, '//yt-formatted-string[@class=\"published-time-text style-scope ytd-comment-renderer\"]')\n",
    "\n",
    "comments_data = []\n",
    "\n",
    "for i in range(len(comments)):\n",
    "    comment = {\n",
    "        \"Comments\": comments[i].text if i < len(comments) else '-',\n",
    "        \"Comment Upvotes\": comment_upvotes[i].text if i < len(comment_upvotes) else '-', \n",
    "        \"Comment Time\": comment_times[i].text if i < len(comment_times) else '-'\n",
    "    }\n",
    "    comments_data.append(comment)\n",
    "\n",
    "comments_data = comments_data[:500]\n",
    "\n",
    "df = pd.DataFrame(comments_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979bd552",
   "metadata": {},
   "source": [
    "9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in\n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall\n",
    "reviews, privates from price, dorms from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0790c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.hostelworld.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0a9eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.find_element(By.CLASS_NAME,'native-input')\n",
    "page.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76fea011",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'item-content')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86908016",
   "metadata": {},
   "outputs": [],
   "source": [
    "web = driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div/div/div/div[5]/button[1]')\n",
    "web.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bacfed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel_name = []\n",
    "distance = []\n",
    "ratings = []\n",
    "total_review = []\n",
    "overall_review = []\n",
    "private_price = []\n",
    "dorms_price = []\n",
    "facilities = []\n",
    "property_desc = []\n",
    "\n",
    "try:\n",
    "    distances = driver.find_elements(By.XPATH,'//span[@class=\"distance-description\"]')\n",
    "    for i in distances:\n",
    "        distance.append(i.text)\n",
    "        \n",
    "except Exception:\n",
    "    distance.append('-')\n",
    "    \n",
    "try:\n",
    "    dorms = driver.find_elements(By.XPATH,'//div[@class=\"property-accommodation-price\"][2]')\n",
    "    for i in dorms:\n",
    "        dorms_price.append(i.text)\n",
    "        \n",
    "except Exception:\n",
    "    dorms_price.append('-')\n",
    "    \n",
    "try:\n",
    "    private = driver.find_elements(By.XPATH,'//div[@class=\"property-accommodation-price\"][1]')\n",
    "    for i in private[2:]:\n",
    "        private_price.append(i.text)\n",
    "        \n",
    "except Exception:\n",
    "    private_price.append('-')\n",
    "    \n",
    "url_list = []\n",
    "urls = driver.find_elements(By.XPATH,'//a[@class=\"nuxt-link\"]')\n",
    "for url in urls:\n",
    "    url_list.append(url.get_attribute('href'))\n",
    "\n",
    "for i in url_list[2:]:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        hostel = driver.find_element(By.XPATH,'//div[@class=\"title-2\"]')\n",
    "        hostel_name.append(hostel.text)\n",
    "        \n",
    "    except Exception:\n",
    "        hostel_name.append('-')\n",
    "        \n",
    "    try:\n",
    "        rating = driver.find_element(By.XPATH,'//div[@class=\"score orange big\"]')\n",
    "        ratings.append(rating.text)\n",
    "        \n",
    "    except Exception:\n",
    "        ratings.append('-')\n",
    "    \n",
    "    try:\n",
    "        reviews = driver.find_element(By.XPATH,'//div[@class=\"reviews\"]')\n",
    "        total_review.append(reviews.text)\n",
    "        \n",
    "    except Exception:\n",
    "        total_review.append('-')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        review = driver.find_element(By.XPATH,'//div[@class=\"keyword\"]')\n",
    "        overall_review.append(review.text)\n",
    "        \n",
    "    except Exception:\n",
    "        overall_review.append('-')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        facility = driver.find_element(By.XPATH,'//ul[@class=\"facility-sections\"]')\n",
    "        facilities.append(facility.text)\n",
    "        \n",
    "    except Exception:\n",
    "        facilities.append('-')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        propertyd = driver.find_element(By.XPATH,'//div[@class=\"content collapse-content\"]')\n",
    "        property_desc.append(propertyd.text)\n",
    "        \n",
    "    except Exception:\n",
    "        property_desc.append('-')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9441b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved successfully\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Hostel Name\": hostel_name,\n",
    "    \"Distance from City Center\" : distance,\n",
    "    \"Rating\": ratings,\n",
    "    \"Total Reviews\": total_review,\n",
    "    \"Overall Reviews\": overall_review,\n",
    "    \"Private from Price\": private_price,\n",
    "    \"Dorms from Price\": dorms_price,\n",
    "    \"Fecilities\" : facilities,\n",
    "    \"Property Description\" : property_desc\n",
    "})\n",
    "df.to_csv(\"hostel_data.csv\", index=False)\n",
    "print(\"Data has been saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4edf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
